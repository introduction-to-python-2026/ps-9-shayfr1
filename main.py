# -*- coding: utf-8 -*-
"""parkinsons.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/yotam-biu/ps9/blob/main/parkinsons.ipynb
"""

# Download the data from your GitHub repository
!wget https://raw.githubusercontent.com/yotam-biu/ps9/main/parkinsons.csv -O /content/parkinsons.csv
!wget https://raw.githubusercontent.com/yotam-biu/python_utils/main/lab_setup_do_not_edit.py -O /content/lab_setup_do_not_edit.py
import lab_setup_do_not_edit

"""

## 1. **Load the dataset:**  

   After running the first cell of this notebook, the file `parkinson.csv` will appear in the `Files` folder.
   You need to loaded the file as a DataFrame.  


"""

import pandas as pd

dframe = pd.read_csv('parkinsons.csv')
dframe = dframe.dropna()
dframe.head()

"""## 2. **Select features:**  

   - Choose **two features** as inputs for the model.  
   - Identify **one feature** to use as the output for the model.  

  #### Advice:  
  - You can refer to the paper available in the GitHub repository for insights into the dataset and guidance on identifying key features for the input and output.  
  - Alternatively, consider creating pair plots or using other EDA methods we learned in the last lecture to explore the relationships between features and determine which ones are most relevant.  

"""

input_features = dframe[['PPE','MDVP:Fo(Hz)']]
output_features = dframe['status']
import plotly.express as px
fig=px.scatter(dframe,x='PPE',y='MDVP:Fo(Hz)',color='status')
fig.show()

"""## 3. **Scale the data:**

   Apply the `MinMaxScaler` to scale the two input columns to a range between 0 and 1.  

"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
x_scales = scaler.fit_transform(input_features)

"""## 4. **Split the data:**

   Divide the dataset into a training set and a validation set.




"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_scales, output_features, test_size=0.2)

"""## 5. **Choose a model:**  

   Select a model to train on the data.  

   #### Advice:  
   - Consider using the model discussed in the paper from the GitHub repository as a reference.  

"""

import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=3)
model.fit(x_train, y_train)

"""# 6. **Test the accuracy:**  

   Evaluate the model's accuracy on the test set. Ensure that the accuracy is at least **0.8**.  

"""

from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, model.predict(x_test))
print(acc)

"""## 7. **Save and upload the model:**  

   After you are happy with your results, save the model with the `.joblib` extension and upload it to your GitHub repository main folder.
   
   Additionally, update the `config.yaml` file with the list of selected features and the model's joblib file name.  


example:  
```yaml
selected_features: ["A", "B"]  
path: "my_model.joblib"  
```
"""

import joblib

joblib.dump(model, 'my_model.joblib')

"""## 8. **Copy the code:**  

   Copy and paste all the code from this notebook into a `main.py` file in the GitHub repository.  

"""
